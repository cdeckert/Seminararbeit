\section{Analyzing Parallelism}

Multithreaded computation can als directed acyclic graph (DAG) betrachtet werden. Dabei ist jede task ein Node. Diese nodes sind durch Kanten miteinander verbunden und representieren auf der einen seite den Predessor und auf der anderen den Successor einer tasks. Der successor hängt von dem Resultat des Predessesors ab. zB ist die conventinal Threads nur eine chain von Nodes wo jeder Node von einem anderen abhängt. Im gegensatz dazu hängt eine solche task von mehreren Subtasks ab.

Einige Berechnungen lassen sich inherrently mehr parallelisieren als andere. Preziesergesagt nehmen wir an, dass alle indivual berechnungsschritte diese selbe Zeit dauern. Das wird als basis Masstatb genutzt. Sei also 
T_P 
die minimale Zeit die benötigt wird um die Ausführung eines programms durchzuführen. Dabei Sei P die menge der dedizierten Prozessoren. T_P gibt somit die Latency an, also die Zeit die es dauert von start bis ende zu laffen. Diese Zeit ist von einem aussenstehenden zu messen. Diese ausf¨hrung kann limitiert sein zB durch die limitierung des Speichers.Einige values von T sind so wichtig, dass sie einen speziellen Namen haben T_1, die numer des Schritts needed um das programm auf einem einzelenen processor auszuführen ist die Brechnungs WORK. Work ist auch die gesamte anzahl an schritten die in einer berechnung benötig werden. 

Dann gilt T_p >= T_1 / P

Ein anderes Extrem ist T_inf, die anzahl der schritte des Programms ist unendlich. Das wird critical-path-length genannt weill endliche Resourcen nicht besser sein können als unendliche Ressourcen. T_P >= T_inf.


Der Speedup von P processors ist diese Ratio T_1 / T_P


Sagen wir mal eine Berechnung speedup linear wenn T_1/T_P = O(P). Der maximale mögliche SPeedup von Parallelism ist T_1/T_inf. 

Diese Daten werden anhalt des Matrizenproblems erklärt. Sei A_P(N) die anzahl der schritte die benätigt werden auf P prozessoren. 


Die Work für A_1(n) = A_1(n) = 4A1(n/2)+O(1) = O(n^2)

Das ist die selbe Arbeit wie notwendig ist bei einem Doppel-Loop.


Die kritische Pfadlänge ist gegeben durch A_if(n) = A_inf(n/2)+O(1) = O(log n).


Sei also M_P(n) die anzahl der scrhitte die zur Multiplikation von zwei n x n matritzen notwendig sind auf P prozessoren. Dann ist die Arbeit gegebnen durch M_1(n) 

also sei
M_1(n) = 8M_1(n/2) + 4A_1(n)

M_1(n) = 8M_1(n/2) + O(n^2)
= O(n^3)


Diese arbeit ist die gleiche wi bei einer conventionallen 3-nested loop implementierung. Die halb grössen Multiplikation kann gleichzeitig stattfinden daher ist der kritische pfad

M_inf(n) = M_inf(n/2)+A_inf(n)

= M_if(n/2) + O(log n)
= O(log^2 n)

Die parallesierung für eine Matrix multiplikation ist gegeben durch M_1(n) / M_inf(n) = O(n^3 / log^2 n)


Zur verdeutlichung wird nun eine 1000 x 1000 matrixen gewählt. Hier kann man bei 
n^3 = 10^9 
auf konventionellem und log 1000 was ca 10 ist ausgehen. Anders gesagt der wahrscheinliche weg sind 
10^9/10^2 = 10^7 
ist. Das ist ungefähr gesprochen so: Die Berechnung könnte eine Millionen prozessoren busy halten. Das ist natürlich viel mehr als was wir in der näheren Zukunft an Multiprozessoren erwarten können. 


Man sollte nicht vergessen, dass es sich hierbei um einen Stark idealisierten Fall handelt. Beispielsweise wurden Idle threads nicht wirklich betrachtet. Darüberhinaus handelt es sich um ein programm, das mehr prozessor als memory benötigt. dadurch performt es besser weil weniger page faults entstehen. Die eigentliche performance of multithreaded computations bleibt auch weiterhin ein komplexes thema. Aber iese art von Analye kann helfen das problem zu lösen.