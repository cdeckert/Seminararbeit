\section{Analyzing Parallelism}

Im folgenden Abschnitt werden basierend auf der Arbeit von Blumofe ein Modell zur Multithreading Berechnung, drei fundameltale Parameter von Multithreading, Arbeit, Berechnungstiefe und Aktivierungstiefe, und darauf basierende Theoreme eingeführt.

Blumofe geht in seiner Arbeit XY davon aus, dass einzelne Aufgaben in eigenen Threads ausgeführt werden. Es handelt sich somit nicht um ein XY sondern um ein YX System, wobei die grundlegende Erkenntnis nicht durch die von Blumofe gewählte Technik beeinträchtigt ist.
Eine Multithreading Berechnung besteht aus einer Menge von Aufgaben. Jede dieser Aufgaben besteht aus untergeordneten Teilaufgaben, die in aufeinander folgender Reihenfolge durch beispielsweise einen Thread ausgeführt werden. Sobald alle Teilaufgaben erledigt sind, gilt auch die Aufgabe als erledigt. In Abbildung 1 ist sind solche Aufgaben grau hinterlegt dargestellt. Einzelne Teilaufgaben sind als Kreise dargestellt. Sie müssen in sequenzieller Reihenfolge (von links nach rechts) ausgeführt werden, was durch sog. fortfahrenden Kanten dargestellt wird.
Während des Ausführens einer solchen Aufgabe ist es möglich, dass andere Aufgaben generiert werden, die parallel zur bestehenden Aufgabe ausgeführt werden können. Diese werden als Kinder einer Aufgabe bezeichnet. Bei der Erstellung einer solchen Kind-Aufgabe wird im Arbeitsspeicher eine gewisse Menge an Platz reserviert, der als Aktivierungs-Datenblock bezeichnet wird. Dieser wird erst wieder freigegeben sobald Zur Berechnung einer Aufgabe ist es möglich, dass Ergebnisse der Kinder-Aufgaben herangezogen werden sog. Daten-Abhängigkeitskanten. In Abbildung 1 ist die Erstellung einer solchen Kind-Aufgabe und das zurückliefen eines Ergebnisses zwischen den Knoten X1 und X2 bzw. X3 und X4 durch einen Pfeil gekennzeichnet.
Eine Teilaufgabe bzw. Aufgabe ist erst dann bereit fertiggestellt zu werden, falls alle vorherigen (Teil-)Aufgaben bereits beendet wurden. Eine Ausführungsreihenfolge der einzelnen Aufgaben, die dies sicherstellt wird als korrekte Ausführungsreihenfolge bezeichnet. 

Basierend auf diesem Baum können die verschiedenen Parameter eines Mutlithreading Programms (Arbeit, Berechnungstiefe und Aktivierungstiefe) beschrieben werden. Zuerst wird der Begriff der Arbeit und Berechnungstiefe eingeführt. Beide Begriffe stehen in Beziehung zur eigentlichen Ausführungszeit, danach kontentieren wir uns auf die Aktivierungstiefe, die mit dem benötigten Speicher in Beziehung steht.

Die Parameter Arbeit und Berechnungstiefe basieren auf dem bereits dargestellten Graphstruktur einer Multithread-Berechnung. Basierend auf den Abhängigkeiten zwischen den Teilaufgaben und den Teilaufgaben selbst kann ein azyklischer gerichterter Graph gebildet werden (Abbildung 2). Als Arbeit wird in einem solchen Graphen die Gesamtanzahl aller Teilaufgaben bezeichnet. Sie entspricht der Anzahl der Berechnungsschritte, die durch einen einzelnen Prozessor benötigt wird. Die Anzahl der Teilaufgaben auf dem längsten gerichteten Pfad (kritischer Pfad) wird als Berechnungstiefe bezeichnet.

Die Zeit, die zur Ausführung eines Programmes benötigt wird, lässt sich quantifizieren durch die Ausführungszeit auf $P$-Prozessoren. Wobei ein Prozessor genau eine Aufgabe gleichteitig durchführen kann. Daher sei die Zeit, die zur Berechnung einer Aufgabe von $P$ Prozessoren benötigt wird

$T_P = min_x T_P(X)$.

Da bei der Berechnung auf nur einem Prozessor $T_1$ in jedem Zeitabschnitt nur eine Aufgabe abgearbeitet werden kann, wird $T_1$ auch als _Arbeit_ bezeichnet. Da die Dauer der Berechnung auf \inf-Prozessoren durch den kritischen Pfad bestimmt ist, wird T_\inf auch als Berechnungstiefe bezeichnet.

Einige Werte von $T$ werden speziell bezeichnet. So wird $T_1$, die Zeit zur Berechnung von allen Teilaufgaben auf einem einzelnen Prozessor auch als Arbeit bezeichnet. Sie ist, wenn man vereinfacht von einer konstanzen Zeit für jede Berechnung ausgeht, gleich der Anzahl der Berechnungsschritte. In einem Zeitschritt können $P$ Prozessoren maximal $P$ Berechnungsschritte durchführen so gilt: $T_P >= T_1/P$


Ein anderes Beispiel für eine solche Zahl ist der kritische Pfad der auch als... bezeichnet wird.


Der Speedup auf $P$ Prozessoren wird als Ratio aus $T_1/T_P$. Dabei hat eine Berechnung einen linearen Speedup falls $T_1/T_P = O(P)$ ist. Der maximal erreichbare speedup ist $T_1/T_\inf$




Wie bereits zuvor beschrieben können Aufgaben eines Multithreading Programms abhängig von anderen Aufgaben sein. XY schlägt daher vor Multithreading Prgramme als gerichteten azyklischen Graphen (GAG) zu betrachten. Jede Aufgabe wird in einem solchen Graphen als Knoten dargestellt. Die möglichen Abhängigkeiten zwischen einzlnen Aufgaben werden als Kanten dargestellt. Dabei können mehrere Aufgaben je ein Successor bzw. Predessesor für eine andere Task sein.

Eine Aufgabe kann nur dann gestartet werden, wenn auch alle Successoren für diese Task bereits ausgeführt wurden. 

Um die Analyse eines parallelisierungsproblems zu vereinfachen wird im folgenden davon ausgegangen, dass jede Aufgabe genau gleich lange dauert und ein Prozessor aus genau einem Kern besteht.


Basieren auf einem solchen Graph können diverse Werte ermittelt werden, die zur Analyse des Parallelisierungsproblems benötigt werden. 

Die Durchlaufzeit (engl. ) bezeichnet die Anzahl der Schritte die ben





Multithreaded computation can als directed acyclic graph (DAG) betrachtet werden. Dabei ist jede task ein Node. Diese nodes sind durch Kanten miteinander verbunden und representieren auf der einen seite den Predessor und auf der anderen den Successor einer tasks. Der successor hängt von dem Resultat des Predessesors ab. zB ist die conventinal Threads nur eine chain von Nodes wo jeder Node von einem anderen abhängt. Im gegensatz dazu hängt eine solche task von mehreren Subtasks ab.

Einige Berechnungen lassen sich inherrently mehr parallelisieren als andere. Preziesergesagt nehmen wir an, dass alle indivual berechnungsschritte diese selbe Zeit dauern. Das wird als basis Masstatb genutzt. Sei also

T_P 

die minimale Zeit die benötigt wird um die Ausführung eines programms durchzuführen. Dabei Sei P die menge der dedizierten Prozessoren. 

T_P

 gibt somit die Latency an, also die Zeit die es dauert von start bis ende zu laffen. Diese Zeit ist von einem aussenstehenden zu messen. Diese ausf¨hrung kann limitiert sein zB durch die limitierung des Speichers.Einige values von T sind so wichtig, dass sie einen speziellen Namen haben 

 T_1,

 die numer des Schritts needed um das programm auf einem einzelenen processor auszuführen ist die Brechnungs WORK. Work ist auch die gesamte anzahl an schritten die in einer berechnung benötig werden. 

Dann gilt T_p >= T_1 / P

Ein anderes Extrem ist 
T_inf, 
die anzahl der schritte des Programms ist unendlich. Das wird critical-path-length genannt weill endliche Resourcen nicht besser sein können als unendliche Ressourcen. 
T_P >= T_inf.


Der Speedup von P processors ist diese Ratio T_1 / T_P


Sagen wir mal eine Berechnung speedup linear wenn 
T_1/T_P = O(P)

. Der maximale mögliche SPeedup von Parallelism ist 

T_1/T_inf. 

Diese Daten werden anhalt des Matrizenproblems erklärt. Sei A_P(N) die anzahl der schritte die benätigt werden auf P prozessoren. 


Die Work für A_1(n) = A_1(n) = 4A1(n/2)+O(1) = O(n^2)

Das ist die selbe Arbeit wie notwendig ist bei einem Doppel-Loop.


Die kritische Pfadlänge ist gegeben durch 

A_if(n) = A_inf(n/2)+O(1) = O(log n).


Sei also M_P(n) die anzahl der scrhitte die zur Multiplikation von zwei n x n matritzen notwendig sind auf P prozessoren. Dann ist die Arbeit gegebnen durch M_1(n) 

also sei
M_1(n) = 8M_1(n/2) + 4A_1(n)

M_1(n) = 8M_1(n/2) + O(n^2)
= O(n^3)


Diese arbeit ist die gleiche wi bei einer conventionallen 3-nested loop implementierung. Die halb grössen Multiplikation kann gleichzeitig stattfinden daher ist der kritische pfad

M_inf(n) = M_inf(n/2)+A_inf(n)

= M_if(n/2) + O(log n)
= O(log^2 n)

Die parallesierung für eine Matrix multiplikation ist gegeben durch M_1(n) / M_inf(n) = O(n^3 / log^2 n)


Zur verdeutlichung wird nun eine 1000 x 1000 matrixen gewählt. Hier kann man bei 
n^3 = 10^9 
auf konventionellem und log 1000 was ca 10 ist ausgehen. Anders gesagt der wahrscheinliche weg sind 
10^9/10^2 = 10^7 
ist. Das ist ungefähr gesprochen so: Die Berechnung könnte eine Millionen prozessoren busy halten. Das ist natürlich viel mehr als was wir in der näheren Zukunft an Multiprozessoren erwarten können. 


Man sollte nicht vergessen, dass es sich hierbei um einen Stark idealisierten Fall handelt. Beispielsweise wurden Idle threads nicht wirklich betrachtet. Darüberhinaus handelt es sich um ein programm, das mehr prozessor als memory benötigt. dadurch performt es besser weil weniger page faults entstehen. Die eigentliche performance of multithreaded computations bleibt auch weiterhin ein komplexes thema. Aber iese art von Analye kann helfen das problem zu lösen.