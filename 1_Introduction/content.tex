\section{Einleitung}


Der folgende Text beschäftigt sich mit der Zerlegung von Problemen in einzelne Komponenten, die parallel ausgeführt werden können. Dabei werden die daraus entstehenden Herausforderungen und Lösungen aufgezeigt.

Bei der Parallelisierbarkeit von Programmen lässt sich grob zwischen drei Arten von Problemen unterscheiden. (1) Probleme, die sich natürlich in einzelne Threads aufteilen. Zu diesen zählen beispielsweise Web-Server, die pro Request einen eigenen Thread starten können. (2) Producer-Consumer-Probleme bei denenen Ergebnisse von einem Producer generiert werden und von einem Konsumenten verarbeitet werden. Im folgenden Text konzentrieren wir uns auf Probleme, deren Möglichkeit zur Parallelisierung in ihnen selbst innewohnt.

Das Ziel bei der Parallelsierung von Inhalten ist es nicht nur das Programm in einzelnen parallelsierbare Teile aufzuteilen, sondern dies auch auf einem effektivem Weg zu tun und dabei die entstehenden Threads zu managen.

Als Beispiel für ein solches Problem ist die Multiplikation von Matrizen.

(C) = (A) * (B)

c_ij = \sum{k=0}^{n-1} a_ik * b_kj


Die einfachste Möglichkeit dieses Problem zu parallelisieren ist es für jedes einzelne Ergebnis c_ij
einen eigenen Thread zu starten.

Eine solche Implementierung ist jedoch wenig ideal, vergleichweise viele kurzlebige Threads müssen gestartet und wieder beendet werden. Dadurch tritt nicht nur beim Schedulen der einzelnen Threads, da jeder Thread eine bestimmte Resourcen benötigt wie beispielsweise Arbeitsspeicher, Zeit zum Setup und Teardown eines Thread sowie Scheduler overhead.

Dadurch entsteht eine ungünstiges Verhältnis zwischen zu leistender Arbeit und damit verbundenem Overhead.

Um das Verhältnis zwischen Overhead und eigentlich zu leistender Arbeit zu reduzieren, können Task-Pools eingesetzt werden.






Ein ansatz um ein solches Problem zu lösen ist die erstellung sog. Task pools. Mehrere kurzlebige Tasks werden in diesen Pool übergeben. Einzelne Worker bedienen sich aus diesem Pool und liefern die berechneten Ergebnisse zurück. Ein weiterer Benefit dieses Systems ist, dass sie unabhängig von externen Faktoren wie uni-core, small-scale und large scale Multiprocessoren verarbeitet werden können. Je nach gegebenem Umfeld kann die optimale Anzahl an workern gestartet werden, die wiederum tasks abarbeiten.

Diese Thread pools werden in Java executor service genannt. Tasks die keine Ergebnisse zurückliefern werden als Runnable objects gespeichert und durchgeführt indem die methode run() aufgerufen wird. Tasks die ein ergebnis zurückliefern werden als Callables implementiert. Diese Services werden per call aufgerufen. Und können sig fucture<t>s zurückliefern. Ein solches Future ist das Versprechen, dass ein gewisses Resultat asynchron geliefert wird, wenn es berechnet wurde. Das Vertrauen, dass ein solches Versprechen eingehalten wird, kann uU enttäuscht werden. Diese Objekte beinhalten eine get() Methode, die das resultat zurückliefern. Ausserdem beinhaltet ein solches Future auch eine Methode um eine task abzubrechen. Das Submitten einer Runnable task retuniert ebenfalls ein Fucture. Das ausführen eines futures garantiert nicht, dass eine task auch tatsächlich parallel ausgeführt wird. Diese methoden sind "advisory". Sie erählen den darunterliegenden Exectuoren, dass sie vielleicht parallel ausgeführt werden könnte.

Im falle der Matritzen multiplikation werden die partitzen in n/2 by n/2 submatrizen gespeichert. Das geisst in Java backed. Diese reflektieren das orginal. 

Die Jobs werden parallel durchgeführt. Jede dieser matritzen kann weiter gespatet werden und dann wieder in einen pool übergeben werden. 


Fibunacci beispiel.


